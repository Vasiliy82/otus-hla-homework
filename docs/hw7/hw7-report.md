Применение In-Memory СУБД
Цель:
В результате выполнения ДЗ вы перенесете хранение одного из модулей вашего приложения в In-Memory СУБД.  
В данном задании тренируются навыки:
- администрирование In-Memory СУБД;
- разработка хранимых процедур для In-Memory СУБД.
Описание/Пошаговая инструкция выполнения домашнего задания:
**Инструкция:**  
Для выполнения ДЗ понадобится In-Memory СУБД с поддержкой функциональности application server (возможность выполнять UDF над данными) - Tarantool. Redis, Apache Ignite, Hazelcast, …
1. Выбрать один из модулей приложения: например диалоги
2. Провести нагрузочное тестирование этого модуля для дальнейшего сравнения
3. Вынести хранение данных из SQL БД в In-Memory СУБД. Перенести логику из модуля в UDF в In-Memory СУБД.  
    Например: для общения с tarantool'ом использовать процедуры (функции lua), не использовать прямые запросы в space'ы при помощи драйвера.
4. Провести нагрузочное тестирование снова
5. Сравнить результаты нагрузочного тестирования

---
  
**Форма сдачи ДЗ**

- Предоставить ссылку на исходный код (github, gitlab, etc)
- Предоставить докеризированное приложение, которое можно запустить при помощи docker-compose (может лежать рядом с исходным кодом) ИЛИ развернутое приложение, доступное извне ИЛИ инструкция по запуску
  
Критерии оценки:

Оценка происходит по принципу зачет/незачет.  
Требования:

1. Один из модулей вынесен в In-Memory СУБД.
2. Логика перенесена из модуля в UDF в In-Memory СУБД (например, общение с tarantool'ом происходит при помощи хранимых процедур (lua-функции)).
3. Проведено нагрузочное тестирование и есть сравнение ДО и ПОСЛЕ.

  

Компетенции:

- In-Memory вычисления
    - - использовать in-memory СУБД redis
    - - использовать in-memory СУБД tarantool


## Отчет о проделанной работе

### Выбор модуля, подлежащего переводу на in-memory, и  in-memory СУБД

Для тестирования и сравнения in-memory СУБД был выбран модуль **`dialogs`**, который отвечает за работу с пользовательскими диалогами: получение списка диалогов, загрузка сообщений из диалога и сохранение новых сообщений. Этот модуль был выбран по нескольким причинам:

1. **Высокая нагрузка при активной переписке**:  
    В социальные сети пользователи часто отправляют и получают большое количество сообщений в реальном времени. Это создает высокую нагрузку на модуль, особенно в периоды пиковых активностей. Такой сценарий идеально подходит для проверки производительности in-memory СУБД.
    
2. **Ограниченный объем данных**:  
    Несмотря на высокую частоту операций, объем данных, обрабатываемых модулем `dialogs`, относительно невелик. Большинство сообщений имеют небольшой размер, а история переписки может быть ограничена определённым количеством сообщений (например, последние 1000 сообщений). Это делает модуль подходящим для in-memory решений, которые хорошо работают с такими объемами данных.
    
3. **Критичная потребность в скорости обработки**:  
    Для модуля диалогов особенно важна **низкая задержка** при записи и чтении данных. Пользователь ожидает моментальной отправки и получения сообщений, что делает выбор in-memory СУБД обоснованным.
    

В рамках работы были рассмотрены следующие in-memory СУБД:

- **Redis и его клоны**  
    Redis — одно из самых популярных in-memory решений, известное своей простотой и высокой скоростью. Однако, его функциональность ограничена по сравнению с другими СУБД, и требуется дополнительная логика на стороне приложения для сложных операций с данными.
    
- **Memcached**  
    Memcached эффективен для кеширования данных, но имеет ограниченные возможности для сложных операций с данными, таких как транзакции или сложные запросы. Это делает его менее подходящим для хранения и обработки сообщений.
    
- **Apache Ignite**  
    Ignite предлагает расширенные возможности для распределенного хранения данных, но сложность настройки и управления делает его менее удобным для тестирования и внедрения в сравнении с другими решениями.
    
- **Hazelcast**  
    Hazelcast — мощная распределенная in-memory платформа, но требует более сложной интеграции и настройки. Она больше подходит для крупных распределённых систем.
    
- **Tarantool**  
    Tarantool был выбран как основная in-memory СУБД для тестирования. Это **гибридная in-memory база данных** с встроенной поддержкой **Lua-скриптов** и **User Defined Functions (UDF)**, что позволяет перенести часть логики работы с данными внутрь СУБД. Tarantool сочетает в себе высокую производительность и гибкость, что делает его отличным выбором для работы с модулями, требующими обработки больших объемов данных с минимальной задержкой.
    

Модуль **`dialogs`** был выбран для тестирования in-memory СУБД из-за его высокой нагрузки при сравнительно небольших объемах данных и критичных требований к скорости обработки. Среди рассмотренных СУБД выбор пал на **Tarantool** благодаря его гибкости, высокой производительности и возможности выполнения сложной логики на стороне базы данных с помощью встроенных функций.

### Доработка микросервиса dialogs

Основные доработки
- **Добавлена поддержка Tarantool как in-memory хранилища.**
    [infrastructure](https://github.com/Vasiliy82/otus-hla-homework/blob/027145f959d9fccfb682e64851fb9a59e9a76eb8/backend/internal/infrastructure/tarantool/tarantool.go#L1-L19)
    [repository](https://github.com/Vasiliy82/otus-hla-homework/blob/027145f959d9fccfb682e64851fb9a59e9a76eb8/backend/internal/repository/dialog_tar.go#L1-L81)
    
- **Добавлена возможность переключения между PostgreSQL и Tarantool.**  
    [main.go](https://github.com/Vasiliy82/otus-hla-homework/blob/027145f959d9fccfb682e64851fb9a59e9a76eb8/backend/cmd/messages/main.go#L69-L87)
      
- **Вынесена логика работы с сообщениями в Lua-функции внутри Tarantool.**  
    [init.lua](https://github.com/Vasiliy82/otus-hla-homework/blob/027145f959d9fccfb682e64851fb9a59e9a76eb8/backend/tarantool/scripts/init.lua#L1-L116)

### Нагрузочное тестирование
Целью нагрузочного тестирования было **сравнение производительности** модуля `dialogs` при работе с **реляционной СУБД (PostgreSQL)** и **in-memory СУБД (Tarantool)**. Для этого использовался **JMeter**, позволяющий моделировать различные профили нагрузки.
#### Сценарий тестирования

**Инструмент:** Apache JMeter  
**Продолжительность теста:** 2 минуты на каждый профиль нагрузки  
**Профили нагрузки:** 2, 10, 100 и 1000 потоков  
**Тестируемые конфигурации:**

- **PostgreSQL** (реляционная СУБД)
- **Tarantool** (in-memory СУБД)
#### Описание тестов в JMeter
Тесты включали в себя три основные операции с сервисом `dialogs`:
1. **Получение списка всех диалогов пользователя**:
    - GET-запрос к `/api/dialog`
2. **Получение сообщений из конкретного диалога**:
    - GET-запрос к `/api/dialog/{friend_id}/list`
3. **Отправка нового сообщения**:
    - POST-запрос к `/api/dialog/{friend_id}/send`
Параметры теста задавались через переменные командной строки:
- **`HOSTNAME`** — адрес хоста сервиса (использовалось `host.docker.internal` для доступа из контейнера JMeter).
- **`PORT`** — порт сервиса (`8081`).
- **`THREADS`** — количество потоков (2, 10, 100, 1000).
- **`DURATION`** — продолжительность теста (2 минуты).

#### Сценарий запуска тестов
Тесты запускались с использованием Docker и JMeter в автоматизированном режиме через Makefile. Для каждого профиля нагрузки тесты проводились как для PostgreSQL, так и для Tarantool.

**Фрагмент Makefile:**

```makefile
# Тестирование для PostgreSQL
for THREADS in $(THREADS_LIST); do \
	echo "Тестирование PostgreSQL с потоками: $$THREADS"; \
	docker run --add-host=host.docker.internal:host-gateway \
		--rm -v $$(pwd):/jmeter -w /jmeter $(JMETER_IMAGE) \
		-n -t $(JMETER_FILE) \
		-JHOSTNAME=host.docker.internal \
		-JPORT=8081 \
		-JTHREADS=$$THREADS \
		-JDURATION=120 \
		-l $(RESULTS_DIR)/postgresql/result_$$THREADS.jtl \
		-e -o $(HTML_REPORT_DIR)/postgresql/report_$$THREADS; \
done
```

### Анализ результатов и итоги нагрузочного тестирования

Результаты тестов сохранялись в виде **JTL-файлов** и **HTML-отчетов** для дальнейшего анализа. Для каждой конфигурации создавались отдельные папки:
- `./jmeter_html_reports/postgresql/`
- `./jmeter_html_reports/tarantool/`
Каждый профиль нагрузки имел свой отчет:
- `report_2`, `report_10`, `report_100`, `report_1000`


**Сводная таблица результатов:**

| Количество потоков | \#Samples PostgreSQL | \#Samples Tarantool | 99th pct PostgreSQL (ms) | 99th pct Tarantool (ms) | Transactions/s PostgreSQL | Transactions/s Tarantool |
| ------------------ | -------------------- | ------------------- | ------------------------ | ----------------------- | ------------------------- | ------------------------ |
| 2                  | 139,425              | 277,543             | 7                        | 2                       | 1,163.32                  | 2,318.58                 |
| 10                 | 419,585              | 766,269             | 9                        | 4                       | 3,500.48                  | 6,392.39                 |
| 100                | 398,532              | 1,394,748           | 153                      | 18                      | 3,326.09                  | 11,645.03                |
| 1000               | 368,985              | 1,557,291           | 517                      | 55                      | 2,955.05                  | 12,644.45                |

**Анализ:**

1. **Производительность (Transactions/s)**:  
    Tarantool значительно опережает PostgreSQL по количеству транзакций в секунду во всех сценариях нагрузки. При 1000 потоках Tarantool демонстрирует почти **4-кратное** преимущество.
    
2. **Задержки (99-й перцентиль)**:  
    Tarantool показывает существенно более низкие задержки, особенно при высокой нагрузке. В то время как у PostgreSQL при 1000 потоках задержка достигает **517 мс**, у Tarantool она остается в пределах **55 мс**.
    
3. **Общее количество обработанных запросов**:  
    Tarantool обрабатывает в **2-4 раза** больше запросов за то же время, что подтверждает его высокую производительность.
    

**Выводы:**

- **Tarantool** как in-memory решение обеспечивает **высокую производительность** и **низкие задержки**, что делает его отличным выбором для сценариев с высокой нагрузкой, таких как обработка сообщений в реальном времени.
- **PostgreSQL** показывает стабильные результаты при умеренной нагрузке, но начинает отставать при увеличении количества потоков, что типично для реляционных СУБД при работе с большим количеством операций записи.


## Как запустить проект

```bash

git clone https://github.com/Vasiliy82/otus-hla-homework.git
git checkout tags/hw7
cd otus-hla-homework/environments/hw07
make up

# nano Makefile
# можно отредактировать Makefile, уменьшив время тестирования (по умолчанию каждый тест длится 120 секунд, итого на 8 тестов уйдет 16 минут), за это отвечает параметр TEST_DURATION.

make run-tests

# Результаты тестирования можно найти в папках:
# ./jmeter_html_reports
# ./jmeter_results

# почистить за собой
make destroy
```
